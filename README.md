# Titanic Logistic Regression

### DataSet From [Kaggle Competition - Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)

- Package: Scikit-Learn
- Loss Function: Cross Entropy
- Use get dummies to convert type of data
- Filter features manually

## Features

![image](https://github.com/yuhexiong/titanic-logistic-regression-python/blob/main/image/features.png)

## Data Distribution

### Age Before fill Null

![image](https://github.com/yuhexiong/titanic-logistic-regression-python/blob/main/image/age-survive-before.png)

### Age After fill Null

![image](https://github.com/yuhexiong/titanic-logistic-regression-python/blob/main/image/age-survive-after.png)

### Sex

![image](https://github.com/yuhexiong/titanic-logistic-regression-python/blob/main/image/sex-survive.png)

### PClass

![image](https://github.com/yuhexiong/titanic-logistic-regression-python/blob/main/image/pclass-survive.png)


## Layer

![image](https://github.com/yuhexiong/digit-recognition-CNN-python/blob/main/image/cnn_layers.png)

## Confusion Matrix - Accuracy Rate 75.84%

![image](https://github.com/yuhexiong/titanic-logistic-regression-python/blob/main/image/confusion_mtx.png)